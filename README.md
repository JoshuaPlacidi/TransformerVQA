# TransformerVQA
[Joshua Placidi](https://www.linkedin.com/in/joshua-placidi/), [Andres Mena](https://www.linkedin.com/in/andresmenagodino/?originalSubdomain=es), [Nikolaos Zavitsanos](https://www.linkedin.com/in/nikolaos-zavitsanos-22561a172/)

*This work was conducted as part of a group coursework project for at the University of Edinburgh.*

TransformerVQA is a image question answering model that only uses transformers to process its multimodal inputs. An overview of the model architecutre can be seen below.
### Video Question (VQ) Encoding
![Defender Model Comparison](/report/figures/m1.svg?raw=true "M1 Model Design")
